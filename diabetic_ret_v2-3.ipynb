{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os.path\n",
    "import numpy as np\n",
    "import itertools\n",
    "import keras.backend as K\n",
    "import keras\n",
    "from IPython.display import clear_output\n",
    "import pandas\n",
    "import time\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeImg(action, x , y):\n",
    "    avgX = x\n",
    "    avgY = y\n",
    "    counter = 0\n",
    "    filelist= [file for file in os.listdir(action + '/') if file.endswith('.jpeg')]\n",
    "    for filename in filelist:\n",
    "    #for filename in itertools.islice(filelist, 0, 100):\n",
    "        img = Image.open(action + '/' + filename)\n",
    "        imgResize = img.resize((avgX, avgY), Image.LANCZOS)\n",
    "        imgResize.save('resized1125x750/' + action + '/' + filename)\n",
    "        img.close()\n",
    "        counter +=1\n",
    "        if (counter % 100) == 0:\n",
    "            clear_output(wait=True)\n",
    "            print(counter, end =\" \") \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resizeImg('train',1125,750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(action, labels_file):\n",
    "    counter = 0\n",
    "    labels = pandas.read_csv(labels_file)\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    filelist= [file for file in os.listdir('resized375x250/' + action + '/') if file.endswith('.jpeg')]\n",
    "    for filename in filelist:\n",
    "    #for filename in itertools.islice(filelist, 0, 1000):\n",
    "        #print(filename)\n",
    "        img = Image.open('resized375x250/' + action + '/' + filename)\n",
    "        #imgData = list(img.getdata())\n",
    "        #imgData = np.asarray(imgData)\n",
    "        #imgData = img.getdata()\n",
    "        #imgData = np.asarray(imgData)\n",
    "        rgbimg = Image.new(\"RGB\", img.size)\n",
    "        rgbimg.paste(img)\n",
    "        imgData = np.asarray(rgbimg)\n",
    "        #imgData = np.asarray(img)\n",
    "        #print(imgData.shape)\n",
    "        #print(imgData.ndim)\n",
    "        if imgData.ndim == 3:\n",
    "            x = imgData.reshape(375,250,3)\n",
    "            X.append(x)\n",
    "            #level = labels.loc[labels['image'] == '11909_right.jpeg']\n",
    "            #print(int(level['level'].values))\n",
    "            #print(filename)\n",
    "            #print(filename[:-5])\n",
    "            #level = labels.loc[labels['image'] == filename[:-5]]#use for train\n",
    "            level = labels.loc[labels['image'] == filename]#use for trainModified\n",
    "            #print(level)\n",
    "            #print(int(level['level'].values))\n",
    "            y.append(int(level['level'].values))\n",
    "        img.close()\n",
    "        counter +=1\n",
    "        if (counter % 100) == 0:\n",
    "            clear_output(wait=True)\n",
    "            print(counter, end =\" \") \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122000 1254.0052473545074\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "X, y = process_image('trainModified', 'trainLabelsModified.csv')\n",
    "elapsed_time = time.time() - start_time\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X: (122053, 375, 250, 3)\n",
      "length of X: 122053\n",
      "shape of y: (122053,)\n",
      "length of y: 122053\n",
      "value of y: 0\n"
     ]
    }
   ],
   "source": [
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "print(\"shape of X: \" + str(X.shape))\n",
    "print(\"length of X: \" + str(len(X)))\n",
    "print(\"shape of y: \" + str(y.shape))\n",
    "print(\"length of y: \" + str(len(y)))\n",
    "print(\"value of y: \" + str(y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split X and y into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test, y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_train: (97642, 375, 250, 3)\n",
      "shape of y_train: (97642,)\n",
      "shape of X_test: (24411, 375, 250, 3)\n",
      "shape of y_test: (24411,)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of X_train: \" + str(X_train.shape))\n",
    "print(\"shape of y_train: \" + str(y_train.shape))\n",
    "print(\"shape of X_test: \" + str(X_test.shape))\n",
    "print(\"shape of y_test: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Saving X_train')\n",
    "# np.save('X_train.npy', X_train)\n",
    "# print('Saving y_train')\n",
    "# np.save('y_train.npy', y_train)\n",
    "# print('Saving X_test')\n",
    "# np.save('X_test.npy', X_test)\n",
    "# print('Saving y_test')\n",
    "# np.save('y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.load('X_train.npy)\n",
    "# y_train = np.load('y_train.npy)\n",
    "# X_test = np.load('X_test.npy)\n",
    "# y_test = np.load('y_test.npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "y_train = to_categorical(y_train, 5)\n",
    "y_test = to_categorical(y_test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.callbacks import ReduceLROnPlateau , ModelCheckpoint , LearningRateScheduler\n",
    "#lr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, epsilon=0.0001, patience=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepath=\"tf_weightsv2-0.hdf5\"\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential , Model\n",
    "from keras.layers import Dense , Activation\n",
    "from keras.layers import Dropout , GlobalAveragePooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD , RMSprop , Adadelta , Adam\n",
    "from keras.layers import Conv2D , BatchNormalization\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use for channels last\n",
    "#X_train=X_train.reshape(5216,250,250,3)\n",
    "X_train=X_train.reshape(97642,375,250,3)\n",
    "X_test=X_test.reshape(24411,375,250,3)\n",
    "#X_train=X_train.reshape(800,375,250,3)\n",
    "#X_test=X_test.reshape(200,375,250,3)\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "# create the base pre-trained model\n",
    "with tf.device('/cpu:0'):\n",
    "    base_model = InceptionV3(weights=None, include_top=False , input_shape=(375, 250, 3))\n",
    "#base_model = InceptionV3(weights=None, include_top=False , input_shape=(375, 250, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = Dropout(0.5)(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "#x = Dropout(0.5)(x)#new\n",
    "#x = Dense(128, activation='relu')(x)#new\n",
    "#x = Dropout(0.5)(x)#new\n",
    "x = BatchNormalization()(x)\n",
    "#x = BatchNormalization(axis=3)(x)#use for channels last\n",
    "#predictions = Dense(2, activation='sigmoid')(x)\n",
    "predictions = Dense(5, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_model = multi_gpu_model(model, gpus=2)\n",
    "parallel_model.compile(loss='categorical_crossentropy', \n",
    "                       optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False), \n",
    "                       metrics=['accuracy'])\n",
    "#model.compile(loss='categorical_crossentropy',\n",
    "#              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
    "#              #optimizer='Adam',\n",
    "#              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train 32 on each GPU\n",
    "batch_size = 64\n",
    "#batch_epochs = 1\n",
    "#total_epochs = 10\n",
    "epochs = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 97642 samples, validate on 24411 samples\n",
      "Epoch 1/12\n",
      "97642/97642 [==============================] - 1407s 14ms/step - loss: 1.5714 - acc: 0.2883 - val_loss: 2.0727 - val_acc: 0.2589\n",
      "Epoch 2/12\n",
      "97642/97642 [==============================] - 1396s 14ms/step - loss: 1.5306 - acc: 0.3173 - val_loss: 1.5160 - val_acc: 0.3348\n",
      "Epoch 3/12\n",
      "97642/97642 [==============================] - 1396s 14ms/step - loss: 1.4297 - acc: 0.3753 - val_loss: 1.5090 - val_acc: 0.3975\n",
      "Epoch 4/12\n",
      "97642/97642 [==============================] - 1397s 14ms/step - loss: 1.2246 - acc: 0.4715 - val_loss: 1.3920 - val_acc: 0.4705\n",
      "Epoch 5/12\n",
      "97642/97642 [==============================] - 1397s 14ms/step - loss: 0.9264 - acc: 0.5834 - val_loss: 0.9445 - val_acc: 0.5819\n",
      "Epoch 6/12\n",
      "97642/97642 [==============================] - 1398s 14ms/step - loss: 0.7464 - acc: 0.6496 - val_loss: 0.8349 - val_acc: 0.6257\n",
      "Epoch 7/12\n",
      "97642/97642 [==============================] - 1397s 14ms/step - loss: 0.6405 - acc: 0.7053 - val_loss: 0.6141 - val_acc: 0.7150\n",
      "Epoch 8/12\n",
      "97642/97642 [==============================] - 1397s 14ms/step - loss: 0.5290 - acc: 0.7623 - val_loss: 0.5612 - val_acc: 0.7361\n",
      "Epoch 9/12\n",
      "97642/97642 [==============================] - 1398s 14ms/step - loss: 0.4297 - acc: 0.8080 - val_loss: 0.4573 - val_acc: 0.7932\n",
      "Epoch 10/12\n",
      "97642/97642 [==============================] - 1396s 14ms/step - loss: 0.3551 - acc: 0.8425 - val_loss: 0.4556 - val_acc: 0.7949\n",
      "Epoch 11/12\n",
      "97642/97642 [==============================] - 1396s 14ms/step - loss: 0.3023 - acc: 0.8687 - val_loss: 0.2862 - val_acc: 0.8716\n",
      "Epoch 12/12\n",
      "97642/97642 [==============================] - 1397s 14ms/step - loss: 0.2547 - acc: 0.8922 - val_loss: 0.3778 - val_acc: 0.8533\n"
     ]
    }
   ],
   "source": [
    "# Since the batch size is 64, each GPU will process 32 samples.\n",
    "history = parallel_model.fit(X_train, y_train, validation_data = (X_test , y_test),\n",
    "                             epochs=epochs, batch_size=batch_size)\n",
    "#history = model.fit(X_train, y_train, validation_data = (X_test , y_test),\n",
    "#                    callbacks=[lr_reduce,checkpoint], epochs=epochs)\n",
    "#history = model.fit(X_train, y_train, validation_data = (X_test , y_test),\n",
    "                    #epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #epoch_counter = 0\n",
    "# for epoch_counter in range(total_epochs):\n",
    "#     if epoch_counter == 0:\n",
    "#         with open('trainHistory2-0.pickle', 'wb') as file_history:\n",
    "#             pickle.dump(history_new.history, file_history)\n",
    "#         print('save model on epoch#' + str(epoch_counter))\n",
    "#         model.save(diabetic_ret_model.h5)\n",
    "#     else:\n",
    "#         with open(r\"trainHistory2-0.pickle\", \"rb\") as input_file: history = Pickle.load(input_file)\n",
    "#         if (history_new['val_acc'][len(history_new['val_acc'])-1]) > (max(history['val_acc'])):\n",
    "#             print('val_acc improved - save model on epoch#' + str(epoch_counter))\n",
    "#             model.save(diabetic_ret_model.h5)\n",
    "#         else:\n",
    "#             print('va_acc did not improve - do not save model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trainHistoryv2-3.pickle', 'wb') as file_history:\n",
    "    pickle.dump(history.history, file_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('diabetic_ret_v2-3-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.models import load_model\n",
    "#model = load_model('tf_weightsv1-0.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights(\"tf_weightsv1-0.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"trainHistoryv2-3.pickle\", \"rb\") as input_file: history = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig1, ax = plt.subplots()\n",
    "ax.plot(history.history['acc'])\n",
    "ax.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "fig2, ax = plt.subplots()\n",
    "ax.plot(history.history['loss'])\n",
    "ax.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1.savefig('acc_v2-3.png')\n",
    "fig2.savefig('loss_v2-3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pred = model.predict(X_test)\n",
    "pred = np.argmax(pred,axis = 1) \n",
    "y_true = np.argmax(y_test,axis = 1)\n",
    "#y_true = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CM = confusion_matrix(y_true, pred)\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "fig, ax = plot_confusion_matrix(conf_mat=CM, figsize=(5, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('cm_v2-3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = 390 / (390 + 137)\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = 390 / (390 + 0)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = (2*recall*precision) / (recall + precision)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-d378793dd341>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_validate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'validate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'validateLabels.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-9ebf61653001>\u001b[0m in \u001b[0;36mprocess_image\u001b[0;34m(action, labels_file)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m#print(level)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m#print(int(level['level'].values))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'level'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "X_validate, y_validate = process_image('validate', 'validateLabels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate = np.asarray(X_validate)\n",
    "print(\"shape of X_validate: \" + str(X_validate.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model2 = load_model('diabetic_ret_v2-3-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model2.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
